{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Metrics Analysis Notebook\n",
    "\n",
    "This notebook mirrors the cleaned workflow from `scripts/metrics_analysis.py`. It:\n",
    "\n",
    "- Loads metrics CSVs for selected activity.\n",
    "- Deduplicates and preprocesses the DataFrame.\n",
    "- Aggregates calibration data.\n",
    "- Produces correlation heatmaps, grouped bar plots, calibration curves, and RMSE rejection curves.\n",
    "\n",
    "Use this for interactive exploration; for batch runs, prefer the script."
   ],
   "id": "2c3f9eee1c1e1d5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "31c35367551603c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from uqdd.metrics import (\n",
    "    group_cols, numeric_cols, string_cols, order_by,\n",
    "    group_order_no_time, hatches_dict_no_time,\n",
    "    accmetrics, accmetrics2, uctmetrics,\n",
    "    aggregate_results_csv,\n",
    "    find_highly_correlated_metrics, plot_metrics, plot_comparison_metrics,\n",
    "    plot_calibration_data, plot_rmse_rejection_curves, plot_auc_comparison,\n",
    "    save_stats_df, plot_pairplot\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_NAME = \"papyrus\"\n",
    "ACTIVITY_TYPE = \"xc50\"  # or 'kx'\n",
    "PROJECT_NAME = \"notebook-run\"\n",
    "COLOR_MAP = \"tab10_r\"\n",
    "COLOR_MAP_2 = None  # defaults to COLOR_MAP if None\n",
    "CORR_CMAP = \"YlGnBu\"\n",
    "SHOW_LEGEND = True\n",
    "\n",
    "COLOR_MAP_2 = COLOR_MAP if COLOR_MAP_2 is None else COLOR_MAP_2\n",
    "\n",
    "# Paths (relative to repo root)\n",
    "repo_root = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))) if os.path.basename(\n",
    "    os.getcwd()) == 'notebooks' else os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "base_path = os.path.join(repo_root, \"uqdd\", \"figures\")\n",
    "\n",
    "project_out_name = PROJECT_NAME\n",
    "TYPE_N_TARGETS = \"all\"\n",
    "DATA_SPECIFIC_PATH = f\"{DATA_NAME}/{ACTIVITY_TYPE}/{TYPE_N_TARGETS}\"\n",
    "\n",
    "file_1 = os.path.join(base_path, \"papyrus\", ACTIVITY_TYPE, \"all\", f\"reassess-runs_ensemble_mcdp_{ACTIVITY_TYPE}\",\n",
    "                      \"metrics.csv\")\n",
    "file_2 = os.path.join(base_path, \"papyrus\", ACTIVITY_TYPE, \"all\", f\"reassess-runs_evidential_{ACTIVITY_TYPE}\",\n",
    "                      \"metrics.csv\")\n",
    "file_3 = os.path.join(base_path, \"papyrus\", ACTIVITY_TYPE, \"all\", f\"reassess-runs_pnn_{ACTIVITY_TYPE}\", \"metrics.csv\")\n",
    "\n",
    "save_dir = os.path.join(base_path, DATA_SPECIFIC_PATH, project_out_name, COLOR_MAP)\n",
    "save_dir_no_time = os.path.join(base_path, DATA_SPECIFIC_PATH, f\"{project_out_name}-no-time\", COLOR_MAP)\n",
    "\n",
    "for p in [save_dir, save_dir_no_time]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "print(\"Input files:\", file_1, file_2, file_3, sep='\\n')\n",
    "print(\"Output dirs:\", save_dir, save_dir_no_time, sep='\\n')"
   ],
   "id": "ae9abd4141ac8387"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and preprocess",
   "id": "c107d817e14ab04a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_1 = pd.read_csv(file_1, header=0)\n",
    "df_2 = pd.read_csv(file_2, header=0)\n",
    "df_3 = pd.read_csv(file_3, header=0)"
   ],
   "id": "bada0dca98fe82b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_main = pd.concat([df_1, df_2, df_3])\n",
    "num_duplicates = df_main.duplicated(subset=[\"wandb run\", \"Task\"]).sum()\n",
    "print(f\"Duplicates found: {num_duplicates}\")\n",
    "\n",
    "df_main = df_main.drop_duplicates(subset=[\"wandb run\", \"Task\"], keep=\"first\")"
   ],
   "id": "8e78398900d431d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Harmonize split names\n",
    "df_main[\"Split\"] = df_main[\"Split\"].apply(lambda x: \"stratified\" if x == \"random\" else x)"
   ],
   "id": "79f6d06571a4c131"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove specific MCDropout rows\n",
    "df_merged = df_main.copy()\n",
    "df_merged = df_merged[~(((df_merged[\"Model type\"] == \"mcdropout\") & (df_merged[\"Split\"] == \"scaffold_cluster\") & (\n",
    "            df_merged[\"dropout\"] == 0.2)))]\n",
    "df_merged = df_merged[~(\n",
    "((df_merged[\"Model type\"] == \"mcdropout\") & (df_merged[\"Split\"] == \"stratified\") & (df_merged[\"dropout\"] == 0.1)))]\n",
    "df_merged = df_merged[\n",
    "    ~(((df_merged[\"Model type\"] == \"mcdropout\") & (df_merged[\"Split\"] == \"time\") & (df_merged[\"dropout\"] == 0.1)))]\n",
    "\n",
    "df_merged[\"Group\"] = df_merged.apply(lambda row: f\"{row['Split']}_{row['Model type']}\", axis=1)"
   ],
   "id": "9fc438a6dcbdbc6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Task subsets\n",
    "df_pcm = df_merged[df_merged[\"Task\"] == \"PCM\"].copy()\n",
    "df_before_calib = df_merged[df_merged[\"Task\"] == \"PCM_before_calibration\"].copy()\n",
    "df_before_calib[\"Calibration\"] = \"Before Calibration\"\n",
    "df_after_calib = df_merged[df_merged[\"Task\"] == \"PCM_after_calibration_with_isotonic_regression\"].copy()\n",
    "df_after_calib[\"Calibration\"] = \"After Calibration\"\n",
    "\n",
    "df_calib = pd.concat([df_before_calib, df_after_calib])\n",
    "df_calib_no_time = df_calib.copy()[df_calib[\"Split\"] != \"time\"]\n",
    "\n",
    "df_no_time = df_pcm.copy()[df_pcm[\"Split\"] != \"time\"]\n",
    "\n",
    "df_pcm.to_csv(os.path.join(save_dir, \"final.csv\"), index=False)\n",
    "df_no_time.to_csv(os.path.join(save_dir_no_time, \"final_no_time.csv\"), index=False)\n",
    "print(df_pcm.shape, df_no_time.shape)"
   ],
   "id": "59197231eaa7237b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aggregate calibration data",
   "id": "cb110025c9bdc6a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_file_path_no_time = os.path.join(\n",
    "    save_dir_no_time, \"final_aggregated_no_time.csv\"\n",
    ")\n",
    "output_file_path = os.path.join(\n",
    "    save_dir, \"final_aggregated.csv\"\n",
    ")"
   ],
   "id": "b5a870f024515224"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "final_aggregated = aggregate_results_csv(df_pcm, group_cols, numeric_cols, string_cols, order_by, output_file_path)\n",
    "final_aggregated[\"Group\"] = final_aggregated.apply(lambda row: f\"{row['Split']}_{row['Model type']}\", axis=1)\n",
    "\n",
    "final_aggregated_no_time = aggregate_results_csv(df_no_time, group_cols, numeric_cols, string_cols, order_by,\n",
    "                                                 output_file_path_no_time)\n",
    "final_aggregated_no_time[\"Group\"] = final_aggregated_no_time.apply(lambda row: f\"{row['Split']}_{row['Model type']}\",\n",
    "                                                                   axis=1)\n",
    "\n",
    "final_aggregated.head()"
   ],
   "id": "cbef16c3571820b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation analysis",
   "id": "e90b6fed656d1aa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "find_highly_correlated_metrics(df_pcm, accmetrics, threshold=0.9, save_dir=save_dir, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)\n",
    "find_highly_correlated_metrics(df_no_time, accmetrics, threshold=0.9, save_dir=save_dir_no_time, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)\n",
    "find_highly_correlated_metrics(df_pcm, uctmetrics, threshold=0.9, save_dir=save_dir, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)\n",
    "find_highly_correlated_metrics(df_no_time, uctmetrics, threshold=0.9, save_dir=save_dir_no_time, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)\n",
    "\n",
    "uctmetrics_uncorr = [\"Miscalibration Area\", \"Sharpness\", \"CRPS\", \"NLL\", \"Interval\"]\n",
    "find_highly_correlated_metrics(df_pcm, uctmetrics_uncorr, threshold=0.9, save_dir=save_dir, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)\n",
    "find_highly_correlated_metrics(df_no_time, uctmetrics_uncorr, threshold=0.9, save_dir=save_dir_no_time, cmap=CORR_CMAP,\n",
    "                               show_legend=SHOW_LEGEND)"
   ],
   "id": "7d2cf0ae303c81fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grouped bar plots",
   "id": "bbf1f87701a982f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "color_dict = plot_metrics(df_no_time, accmetrics, cmap=COLOR_MAP, save_dir=save_dir_no_time,\n",
    "                          hatches_dict=hatches_dict_no_time, group_order=group_order_no_time, fig_width=12,\n",
    "                          fig_height=3, show_legend=SHOW_LEGEND)\n",
    "plot_metrics(df_no_time, accmetrics2, cmap=COLOR_MAP, save_dir=save_dir_no_time, hatches_dict=hatches_dict_no_time,\n",
    "             group_order=group_order_no_time, fig_width=6, fig_height=3, show_legend=SHOW_LEGEND)\n",
    "uctmetrics_uncorr = [\"Miscalibration Area\", \"Sharpness\", \"CRPS\", \"NLL\", \"Interval\"]\n",
    "plot_metrics(df_no_time, uctmetrics_uncorr, cmap=COLOR_MAP, save_dir=save_dir_no_time,\n",
    "             hatches_dict=hatches_dict_no_time, group_order=group_order_no_time, fig_width=10, fig_height=3,\n",
    "             show_legend=SHOW_LEGEND)"
   ],
   "id": "154ae19783bb5221"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pairplots",
   "id": "b44bb2a250bf761b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_pairplot(df_no_time, \"Pairplot for Accuracy Metrics\", accmetrics, save_dir=save_dir_no_time, cmap=COLOR_MAP,\n",
    "              group_order=group_order_no_time, show_legend=SHOW_LEGEND)\n",
    "plot_pairplot(df_no_time, \"Pairplot for Uncertainty Metrics\", uctmetrics, save_dir=save_dir_no_time, cmap=COLOR_MAP,\n",
    "              group_order=group_order_no_time, show_legend=SHOW_LEGEND)"
   ],
   "id": "35cf4f202ddf88cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calibration curves",
   "id": "663b5a05b1d64b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models_order = [\"pnn\", \"ensemble\", \"mcdropout\", \"evidential\", \"eoe\", \"emc\"]\n",
    "plot_comparison_metrics(df_calib_no_time, [\"Miscalibration Area\", \"Sharpness\", \"NLL\", \"CRPS\", \"Interval\"],\n",
    "                        cmap=COLOR_MAP, color_dict=color_dict, save_dir=save_dir_no_time, fig_width=20, fig_height=3,\n",
    "                        show_legend=SHOW_LEGEND)\n",
    "\n",
    "# Overall calibration\n",
    "plot_calibration_data(final_aggregated_no_time, base_path, save_dir_no_time, title=\"Calibration Curves for Models\",\n",
    "                      color_name=COLOR_MAP_2, group_order=group_order_no_time, fig_width=5, fig_height=5,\n",
    "                      show_legend=SHOW_LEGEND)\n",
    "\n",
    "# Per-group\n",
    "for i in range(len(final_aggregated_no_time)):\n",
    "    df_sub = final_aggregated_no_time.iloc[[i]]\n",
    "    plot_calibration_data(df_sub, base_path, save_dir_no_time,\n",
    "                          title=f\"Calibration Curves for {df_sub['Group'].values[0]}\", color_name=COLOR_MAP_2,\n",
    "                          group_order=group_order_no_time, fig_width=5, fig_height=5, show_legend=SHOW_LEGEND)\n",
    "\n",
    "# Per-split\n",
    "for s in final_aggregated_no_time[\"Split\"].unique():\n",
    "    df_split = final_aggregated_no_time[final_aggregated_no_time[\"Split\"] == s]\n",
    "    plot_calibration_data(df_split, base_path, save_dir_no_time, title=f\"Calibration Curves for {s}\",\n",
    "                          color_name=COLOR_MAP_2, group_order=group_order_no_time, fig_width=5, fig_height=5,\n",
    "                          show_legend=SHOW_LEGEND)"
   ],
   "id": "55ff0b363d2d020"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RMSE Rejection curves + AUC comparison",
   "id": "648adf35cac8a0fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "save_dir_plot = os.path.join(save_dir_no_time, \"rrcs\")\n",
    "os.makedirs(save_dir_plot, exist_ok=True)\n",
    "\n",
    "uct_types = [\"aleatoric\", \"epistemic\", \"both\"]\n",
    "for uct_t in uct_types:\n",
    "    for normalize_rmse in [True, False]:\n",
    "        add_to_title = (\"-normalized\" if normalize_rmse else \"\") + \"-\" + uct_t\n",
    "        stats_df = plot_rmse_rejection_curves(df_no_time, base_path, cmap=COLOR_MAP_2, save_dir_plot=save_dir_plot,\n",
    "                                              add_to_title=\"all\" + add_to_title, normalize_rmse=normalize_rmse,\n",
    "                                              unc_type=uct_t, max_rejection_ratio=0.95, group_order=group_order_no_time,\n",
    "                                              fig_width=6, fig_height=5, show_legend=SHOW_LEGEND)\n",
    "        plot_auc_comparison(stats_df, cmap=COLOR_MAP, color_dict=color_dict, save_dir=save_dir_plot,\n",
    "                            add_to_title=\"all\" + add_to_title, hatches_dict=hatches_dict_no_time,\n",
    "                            group_order=group_order_no_time, fig_width=4, fig_height=3, show_legend=SHOW_LEGEND)\n",
    "        plot_auc_comparison(stats_df, cmap=COLOR_MAP, color_dict=color_dict, save_dir=save_dir_plot,\n",
    "                            add_to_title=\"all\" + add_to_title + \"-min-0.5\", hatches_dict=hatches_dict_no_time,\n",
    "                            group_order=group_order_no_time, min_y_axis=0.5, fig_width=4, fig_height=3,\n",
    "                            show_legend=SHOW_LEGEND)\n",
    "        save_stats_df(stats_df, save_dir_plot, add_to_title=\"all\" + add_to_title)\n",
    "\n",
    "# Per split (excluding time)\n",
    "df_pcm_stratified = df_pcm[df_pcm[\"Split\"] == \"stratified\"]\n",
    "df_pcm_scaffold = df_pcm[df_pcm[\"Split\"] == \"scaffold_cluster\"]\n",
    "for name, df_sub in [(\"stratified\", df_pcm_stratified), (\"scaffold\", df_pcm_scaffold)]:\n",
    "    for uct_t in uct_types:\n",
    "        for normalize_rmse in [True, False]:\n",
    "            add_to_title = (\"-normalized\" if normalize_rmse else \"\") + \"-\" + uct_t\n",
    "            stats_df = plot_rmse_rejection_curves(df_sub, base_path, cmap=COLOR_MAP_2, save_dir_plot=save_dir_plot,\n",
    "                                                  add_to_title=name + add_to_title, normalize_rmse=normalize_rmse,\n",
    "                                                  unc_type=uct_t, max_rejection_ratio=0.95,\n",
    "                                                  group_order=group_order_no_time, fig_width=6, fig_height=5,\n",
    "                                                  show_legend=SHOW_LEGEND)\n",
    "            plot_auc_comparison(stats_df, cmap=COLOR_MAP, color_dict=color_dict, save_dir=save_dir_plot,\n",
    "                                add_to_title=name + add_to_title, hatches_dict=hatches_dict_no_time,\n",
    "                                group_order=group_order_no_time, fig_width=2, fig_height=3, show_legend=SHOW_LEGEND)\n",
    "            plot_auc_comparison(stats_df, cmap=COLOR_MAP, color_dict=color_dict, save_dir=save_dir_plot,\n",
    "                                add_to_title=name + add_to_title + \"-min-0.5\", hatches_dict=hatches_dict_no_time,\n",
    "                                group_order=group_order_no_time, min_y_axis=0.5, fig_width=2, fig_height=3,\n",
    "                                show_legend=SHOW_LEGEND)\n",
    "            save_stats_df(stats_df, save_dir_plot, add_to_title=name + add_to_title)"
   ],
   "id": "87858149f78ef572"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Special MC Dropout Experiment",
   "id": "f33190fa1452aa8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mcdp_before_calib = df_merged[\n",
    "    (df_merged[\"Model type\"] == \"mcdropout\") & (df_merged[\"Task\"] == \"PCM_before_calibration\")].copy()\n",
    "mcdp_after_calib_iso = df_merged[(df_merged[\"Model type\"] == \"mcdropout\") & (\n",
    "            df_merged[\"Task\"] == \"PCM_after_calibration_with_isotonic_regression\")].copy()\n",
    "mcdp_after_calib_std = df_merged[(df_merged[\"Model type\"] == \"mcdropout\") & (\n",
    "            df_merged[\"Task\"] == \"PCM_after_calibration_with_std_recalibrator\")].copy()\n",
    "mc_group_order = [\n",
    "    \"stratified_mcdropout\",\n",
    "    \"scaffold_cluster_mcdropout\",\n",
    "    \"time_mcdropout\"\n",
    "]\n",
    "\n"
   ],
   "id": "2dd29369ee0125e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now we shall plot the same but to compare the MCDP results\n",
    "plot_metrics(mcdp_before_calib, 'Accuracy Metrics Before Calibration (MCDP)', accmetrics, plot_type='bar',\n",
    "             save_dir=save_dir, group_order=mc_group_order)\n",
    "plot_metrics(mcdp_after_calib_iso, 'Uncertainty Metrics After Calibration (Isotonic Regression) 1 (MCDP)',\n",
    "             uctmetrics, plot_type='bar', save_dir=save_dir, group_order=mc_group_order)\n",
    "\n",
    "plot_metrics(mcdp_after_calib_std, 'Uncertainty Metrics After Calibration (Std Recalibrator) 1 (MCDP)', uctmetrics,\n",
    "             plot_type='bar', save_dir=save_dir, group_order=mc_group_order)\n",
    "\n",
    "# Pair plot\n",
    "plot_pairplot(mcdp_before_calib, 'Pairplot for Accuracy Metrics (MCDP)', accmetrics, save_dir=save_dir)\n",
    "\n",
    "# Comparing Calibration Metrics Before and After Calibration in one plot\n",
    "# Add a column to indicate calibration state\n",
    "mcdp_before_calib['Calibration'] = 'Before Calibration'\n",
    "mcdp_after_calib_iso['Calibration'] = 'After Isotonic Regression'\n",
    "mcdp_after_calib_std['Calibration'] = 'After Std Recalibrator'\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "mcdp_combined = pd.concat([mcdp_before_calib, mcdp_after_calib_iso, mcdp_after_calib_std])\n"
   ],
   "id": "98b12f28e2896274"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Backup and Experimental Code",
   "id": "d92fc485bd49c1e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "\n",
    "# Data preparation\n",
    "data = {\n",
    "    'Parameter': ['weight_decay', 'batch_size', 'lr', 'dropout'],\n",
    "    'Value1': [0.424, 0.287, 0.210, 0.079],\n",
    "    'Value2': [-0.185, -0.093, 0.081, -0.204]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "tbl = Table(ax, bbox=[0, 0, 1, 1])\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(12)\n",
    "\n",
    "# Adding table cells\n",
    "n_rows, n_cols = df.shape\n",
    "width, height = 1.0 / n_cols, 1.0 / (n_rows + 1)\n",
    "\n",
    "# Add header row\n",
    "for col in range(n_cols):\n",
    "    tbl.add_cell(0, col, width, height, text=df.columns[col], loc='center', facecolor='lightgrey')\n",
    "\n",
    "# Add data rows\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        value = df.iloc[row, col]\n",
    "        if col == 0:\n",
    "            tbl.add_cell(row + 1, col, width, height, text=value, loc='center', facecolor='white')\n",
    "        else:\n",
    "            bar_color = 'blue' if value > 0 else 'red'\n",
    "            tbl.add_cell(row + 1, col, width * abs(value), height, text='', loc='left', facecolor=bar_color,\n",
    "                         edgecolor='none')\n",
    "\n",
    "ax.add_table(tbl)\n",
    "# Saving the plot\n",
    "plt.show()"
   ],
   "id": "68a79af3629c0107"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the normal distributions\n",
    "mu1, sigma1 = 7, 0.1  # mean and standard deviation\n",
    "mu2, sigma2 = 7, 0.2\n",
    "mu3, sigma3 = 6, 0.3\n",
    "mu4, sigma4 = 8, 0.4\n",
    "# Generate data points\n",
    "x = np.linspace(5, 9, 1000)\n",
    "y1 = (1 / (sigma1 * np.sqrt(2 * np.pi))) * np.exp(- (x - mu1) ** 2 / (2 * sigma1 ** 2))\n",
    "y2 = (1 / (sigma2 * np.sqrt(2 * np.pi))) * np.exp(- (x - mu2) ** 2 / (2 * sigma2 ** 2))\n",
    "y3 = (1 / (sigma3 * np.sqrt(2 * np.pi))) * np.exp(- (x - mu3) ** 2 / (2 * sigma3 ** 2))\n",
    "y4 = (1 / (sigma4 * np.sqrt(2 * np.pi))) * np.exp(- (x - mu4) ** 2 / (2 * sigma4 ** 2))\n",
    "# Create the plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(x, y1, label=f'$\\mu={mu1}, \\sigma={sigma1}$', linewidth=2)\n",
    "plt.plot(x, y2, label=f'$\\mu={mu2}, \\sigma={sigma2}$', linewidth=2)\n",
    "plt.plot(x, y3, label=f'$\\mu={mu3}, \\sigma={sigma3}$', linewidth=2)\n",
    "plt.plot(x, y4, label=f'$\\mu={mu4}, \\sigma={sigma4}$', linewidth=2)\n",
    "\n",
    "# # Add annotations for sigma\n",
    "# plt.annotate(f'$\\sigma={sigma1}$', xy=(mu1 + sigma1, (1/(sigma1 * np.sqrt(2 * np.pi))) * np.exp( - (sigma1)**2 / (2 * sigma1**2) )), xytext=(mu1 + sigma1 + 1, (1/(sigma1 * np.sqrt(2 * np.pi))) * np.exp( - (sigma1)**2 / (2 * sigma1**2) )),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "#\n",
    "# plt.annotate(f'$\\sigma={sigma2}$', xy=(mu2 + sigma2, (1/(sigma2 * np.sqrt(2 * np.pi))) * np.exp( - (sigma2)**2 / (2 * sigma2**2) )), xytext=(mu2 + sigma2 + 1, (1/(sigma2 * np.sqrt(2 * np.pi))) * np.exp( - (sigma2)**2 / (2 * sigma2**2) )),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "#\n",
    "# plt.annotate(f'$\\sigma={sigma3}$', xy=(mu3 + sigma3, (1/(sigma3 * np.sqrt(2 * np.pi))) * np.exp( - (sigma3)**2 / (2 * sigma3**2) )), xytext=(mu3 + sigma3 + 1, (1/(sigma3 * np.sqrt(2 * np.pi))) * np.exp( - (sigma3)**2 / (2 * sigma3**2) )),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "#\n",
    "# plt.annotate(f'$\\sigma={sigma4}$', xy=(mu4 + sigma4, (1/(sigma4 * np.sqrt(2 * np.pi))) * np.exp( - (sigma4)**2 / (2 * sigma4**2) )), xytext=(mu4 + sigma4 + 1, (1/(sigma4 * np.sqrt(2 * np.pi))) * np.exp( - (sigma4)**2 / (2 * sigma4**2) )),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "# Add title and labels\n",
    "# plt.title('Normal Distributions with Different $\\mu$ and $\\sigma$')\n",
    "plt.xlabel('output')\n",
    "plt.ylabel('Probability Density')\n",
    "# plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(False)\n",
    "# No background\n",
    "plt.gca().set_facecolor('white')\n",
    "# save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('normal_distributions.png', dpi=1200)\n",
    "plt.savefig('normal_distributions.pdf')\n",
    "plt.savefig('normal_distributions.svg')\n",
    "plt.show()"
   ],
   "id": "3954fccaa981d392"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
