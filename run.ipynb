{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from papyrus import Papyrus, PapyrusDataset\n",
    "from chemutils import generate_ecfp, generate_mol_descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from papyrus_scripts.modelling import pcm, qsar\n",
    "import xgboost\n",
    "from torch.utils.data import DataLoader\n",
    "from models.baselines import train_ensemble, train_model, test_model\n",
    "\n",
    "# Import Uncertainty Toolbox\n",
    "import uncertainty_toolbox as uct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# RUN FOR THE FIRST TIME ONLY\n",
    "# papyrus_xc50 = Papyrus(\n",
    "#     path=\"data/\",\n",
    "#     chunksize=1000000,\n",
    "#     accession=None,\n",
    "#     activity_type=[\"IC50\", \"EC50\"],\n",
    "#     protein_class=None,\n",
    "#     verbose_files=True\n",
    "# )\n",
    "# df_xc50 = papyrus_xc50()\n",
    "# df_xc50.to_csv(\"data/papyrus_filtered_high_quality_xc50.csv\", index=False)\n",
    "dtypes = {\n",
    "    \"typeIC50\": 'str', #'int32',\n",
    "    \"typeEC50\": 'str', # 'int32',\n",
    "    \"typeKi\": 'str', # 'int32',\n",
    "    \"typeKd\": 'str', # 'int32',\n",
    "    \"relation\": 'str',\n",
    "    'activityClass': 'str',\n",
    "    \"pchemblValue\": 'str',\n",
    "    \"pchemblValueMean\": 'float64',\n",
    "    \"pchemblValueStdDev\": 'float64',\n",
    "    \"pchemblValueSEM\": 'float64',\n",
    "    \"pchemblValueN\": 'int32',\n",
    "    \"pchemblValueMedian\": 'float64',\n",
    "    \"pchemblValueMAD\": 'float64',\n",
    "}\n",
    "# Read column names from file\n",
    "# cols = list(pd.read_csv(\"data/papyrus_filtered_high_quality_01_standardized.csv\", nrows =1))\n",
    "\n",
    "df_xc50 = pd.read_csv(\n",
    "    \"data/papyrus_filtered_high_quality_01_standardized.csv\",\n",
    "    index_col=0,\n",
    "    header=0,\n",
    "    dtype=dtypes,\n",
    "    # chunksize=100000,\n",
    "    low_memory=False  # , usecols =[i for i in cols if i != 'activityClass']\n",
    ")\n",
    "\n",
    "df_xc50[\"pchemblValue\"] = (\n",
    "    df_xc50[\"pchemblValue\"]\n",
    "    .str.split(\";\")\n",
    "    .apply(lambda x: [float(i) for i in x] if type(x) != float else x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# df_xc50 = pd.read_csv(\"data/papyrus_filtered_high_quality_xc50.csv\")\n",
    "# df_xc50 = generate_ecfp(df_xc50, 2, 1024, False, False)\n",
    "# df_xc50.to_csv(\"data/papyrus_filtered_high_quality_xc50_04_with_ECFP.csv\", index=False)\n",
    "\n",
    "# df_xc50 = generate_mol_descriptors(df_xc50, 'smiles', None)\n",
    "# df_xc50.to_csv(\"data/papyrus_filtered_high_quality_xc50_05_with_molecular_descriptors.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# dtypes = {\n",
    "#     \"typeIC50\": 'str', #'int32',\n",
    "#     \"typeEC50\": 'str', # 'int32',\n",
    "#     \"typeKi\": 'str', # 'int32',\n",
    "#     \"typeKd\": 'str', # 'int32',\n",
    "#     \"relation\": 'str',\n",
    "#     'activityClass': 'str',\n",
    "#     \"pchemblValue\": 'str',\n",
    "#     \"pchemblValueMean\": 'float64',\n",
    "#     \"pchemblValueStdDev\": 'float64',\n",
    "#     \"pchemblValueSEM\": 'float64',\n",
    "#     \"pchemblValueN\": 'int32',\n",
    "#     \"pchemblValueMedian\": 'float64',\n",
    "#     \"pchemblValueMAD\": 'float64',\n",
    "# }\n",
    "#\n",
    "# import pandas as pd\n",
    "# df_xc50 = pd.read_csv(\n",
    "#     \"data/papyrus_filtered_high_quality_xc50_04_with_ECFP.csv\",\n",
    "#     index_col=0,\n",
    "#     header=0,\n",
    "#     dtype=dtypes,\n",
    "#     converters={\"ECFP\": eval,\n",
    "#                 \"pchemblValue\": eval}\n",
    "# )\n",
    "#     # chunksize=100000,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452115, 33)\n",
      "(111574, 33)\n"
     ]
    }
   ],
   "source": [
    "# Filtering the top 25 targets in number of datapoints.\n",
    "# step 1: group the dataframe by protein target\n",
    "print(df_xc50.shape)\n",
    "grouped = df_xc50.groupby('accession')\n",
    "# step 2: count the number of measurements for each protein target\n",
    "counts = grouped['accession'].count()\n",
    "\n",
    "# step 3: sort the counts in descending order\n",
    "sorted_counts = counts.sort_values(ascending=False)\n",
    "\n",
    "# step 4: select the 20 protein targets with the highest counts\n",
    "top_targets = sorted_counts.head(25)\n",
    "\n",
    "# step 5: filter the original dataframe to only include rows corresponding to these 20 protein targets\n",
    "filtered_df = df_xc50[df_xc50['accession'].isin(top_targets.index)]\n",
    "print(filtered_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/3000 -- Training Loss: 0.0003, Validation Loss: 0.2830\n",
      "Epoch 200/3000 -- Training Loss: 0.0001, Validation Loss: 0.2841\n",
      "Stopped early after 229 epochs\n",
      "Epoch 100/3000 -- Training Loss: 0.0004, Validation Loss: 0.2843\n",
      "Epoch 200/3000 -- Training Loss: 0.0001, Validation Loss: 0.2823\n",
      "Stopped early after 227 epochs\n",
      "Epoch 100/3000 -- Training Loss: 0.0004, Validation Loss: 0.2887\n"
     ]
    }
   ],
   "source": [
    "from models.baselines import train_ensemble, train_model, test_model\n",
    "from papyrus import PapyrusDataset\n",
    "# step 6: iterate over the 25 protein targets\n",
    "all_ensembles = dict()\n",
    "for protein_target in top_targets.index:\n",
    "    # create a new dataframe containing only the rows corresponding to the current protein target\n",
    "    target_df = df_xc50[df_xc50['accession'] == protein_target]\n",
    "\n",
    "    train, test = train_test_split(target_df, test_size=0.3, random_state=42)\n",
    "    valid, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dataset = PapyrusDataset(train)\n",
    "    valid_dataset = PapyrusDataset(valid)\n",
    "    test_dataset = PapyrusDataset(test)\n",
    "    # Create DataLoader for training and validation sets\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    ensemble = train_ensemble(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=valid_loader,\n",
    "        test_loader=test_loader,\n",
    "        input_size=1024,\n",
    "        hidden_size1=512,\n",
    "        hidden_size2=128,\n",
    "        hidden_size3=32,\n",
    "        output_size=1,\n",
    "        num_epochs=3000\n",
    "    )\n",
    "    all_ensembles.update({protein_target: ensemble})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest version: 05.6\n",
      "Number of files to be downloaded: 10\n",
      "Total size: 8.25GB\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading version 05.6:   0%|          | 0.00/8.25G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "168b8335bf6c4bebbc02646b8582a0b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/60 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "213276a6bbd5455e9ad275995c3ddd46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bkhalil\\.conda\\envs\\bk-jnj\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "papyrus_kx = Papyrus(\n",
    "    path=\"data/\",\n",
    "    chunksize=1000000,\n",
    "    accession=None,\n",
    "    activity_type=[\"Ki\", \"Kd\"],\n",
    "    protein_class=None,\n",
    "    verbose_files=True\n",
    ")\n",
    "df_kx = papyrus_kx()\n",
    "df_kx.to_csv(\"data/papyrus_filtered_high_quality_kx.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_kx = pd.read_csv(\"data/papyrus_filtered_high_quality_kx.csv\")\n",
    "#\n",
    "# df_kx = generate_ecfp(df_kx, 2, 1024, False, False)\n",
    "# df_kx.to_csv(\"data/papyrus_filtered_high_quality_kx_04_with_ECFP.csv\", index=False)\n",
    "#\n",
    "# df_kx = generate_mol_descriptors(df_kx, 'smiles', None)\n",
    "# df_kx.to_csv(\"data/papyrus_filtered_high_quality_kx_05_with_molecular_descriptors.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtering the top 25 targets in number of datapoints.\n",
    "# step 1: group the dataframe by protein target\n",
    "grouped = df_kx.groupby('accession')\n",
    "# step 2: count the number of measurements for each protein target\n",
    "counts = grouped['accession'].count()\n",
    "# step 3: sort the counts in descending order\n",
    "sorted_counts = counts.sort_values(ascending=False)\n",
    "\n",
    "# step 4: select the 20 protein targets with the highest counts\n",
    "top_targets = sorted_counts.head(25)\n",
    "\n",
    "# step 5: filter the original dataframe to only include rows corresponding to these 20 protein targets\n",
    "filtered_df = df_kx[df_kx['accession'].isin(top_targets.index)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# step 6: iterate over the 25 protein targets\n",
    "for protein_target in top_targets.index:\n",
    "    # create a new dataframe containing only the rows corresponding to the current protein target\n",
    "    target_df = df_xc50[df_xc50['protein_target'] == protein_target]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
